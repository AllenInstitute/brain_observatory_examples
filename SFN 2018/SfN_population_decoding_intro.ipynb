{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/resources/SFN_Logo_2018.png\"> \n",
    "\n",
    "<h1 align=\"center\">Population decoding with the Allen Brain Observatory</h1>\n",
    "\n",
    "<h3 align=\"center\">November 3, 2018</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook:\n",
    "## 1) Getting population responses from a brain observatory experiment \n",
    "## 2) Decoding a visual stimulus from the population activity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "matplotlib.rcParams['font.size'] = 16\n",
    "matplotlib.rcParams['figure.titlesize'] = 16\n",
    "\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os, sys, h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "drive_path = '/Volumes/Brain2018/visual_coding_2p/'\n",
    "manifest_file = os.path.join(drive_path,'manifest.json')\n",
    "boc = BrainObservatoryCache(manifest_file=manifest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What locations (visual areas, cre lines and imaging depths) are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boc.get_all_targeted_structures())\n",
    "print(boc.get_all_cre_lines())\n",
    "print(boc.get_all_imaging_depths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What stimuli are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boc.get_all_stimuli())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an experiment container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an experiment from VISp / Cux2 / L2/3\n",
    "# get raw responses and analysis object with events\n",
    "\n",
    "visual_area = 'VISp'\n",
    "cre_line ='Cux2-CreERT2'\n",
    "imaging_depth = 275\n",
    "exp_ind = 1\n",
    "\n",
    "exps = boc.get_experiment_containers(targeted_structures=[visual_area], cre_lines=[cre_line], imaging_depths=[imaging_depth])\n",
    "exp_cont = exps[exp_ind]\n",
    "\n",
    "print('Number of experiment containers: '+str(len(exps)))\n",
    "print(exps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an experimental session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_cont_id = exps[exp_ind]['id']\n",
    "expt = boc.get_ophys_experiments(experiment_container_ids=[exp_cont_id], stimuli=['drifting_gratings'])[0]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the physiology data from that experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = boc.get_ophys_experiment_data(ophys_experiment_id=expt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_t, dff = data_set.get_dff_traces()\n",
    "events = boc.get_ophys_experiment_events(ophys_experiment_id=expt)\n",
    "\n",
    "print(dff.shape)\n",
    "print(events.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "plt.plot(dff_t, dff[0], label='Df/f'); plt.plot(dff_t, events[0], label='Events'); \n",
    "plt.xlabel('Time (s)'); plt.ylabel('Df/f'); plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many neurons were segmented from this imaging experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = dff.shape[0]\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1);\n",
    "for i in range(10):\n",
    "    ax.plot(dff_t, events[i]+i, color='k')\n",
    "ax.set_xlabel('Time (s)'); ax.set_ylabel('Event size (df/f)');\n",
    "ax.set_yticks([]); sns.despine(fig)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the stimuli in this experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.list_stimuli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_table = data_set.get_stimulus_table('drifting_gratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(stim_table))\n",
    "print(stim_table[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the population activity together with the stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1);\n",
    "for i in range(10):\n",
    "    ax.plot(dff_t, events[i]+i, color='k')\n",
    "\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "norm = matplotlib.colors.Normalize(vmin=-45., vmax=315.)\n",
    "normY = norm(stim_table['orientation'])\n",
    "\n",
    "Nstim = len(stim_table)\n",
    "\n",
    "for n in range(Nstim):\n",
    "    start, end = stim_table['start'][n], stim_table['end'][n]\n",
    "    plt.axvspan(xmin=dff_t[start], xmax=dff_t[end], color=cmap(normY[n]), alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Time (s)'); ax.set_ylabel('Event size (df/f)');\n",
    "ax.set_xlim((dff_t[stim_table['start'][0]], dff_t[stim_table['end'][20]]))\n",
    "ax.set_yticks([]); sns.despine(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we relate the population activity to the stimulus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"decode_fig.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear discriminant analysis (LDA): a probabilistic model of population responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' Rule tells us how to decompose joint probabilities: <br>\n",
    "\n",
    "\\begin{equation} \\begin{aligned} \n",
    "\\Large P(x, y) = P(y | x ) \\, P(x) \n",
    "\\end{aligned} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} \\begin{aligned} \n",
    "\\Large P(y | x ) = \\frac{P(x|y) P(y)}{P(x)}\n",
    "\\end{aligned} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} \\begin{aligned} \n",
    "\\Large P(y | x ) = \\frac{P(x|y) P(y)}{\\sum_y P(x|y)P(y)}\n",
    "\\end{aligned} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA corresponds to a Gaussian $P(x|y)$, along with the assumption that the covariance does not depend on $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get X!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_path = os.path.join(drive_path,'ophys_experiment_analysis')\n",
    "analysis_file = os.path.join(analysis_path, str(expt)+'_three_session_A_analysis.h5')\n",
    "mean_sweep_response = pd.read_hdf(analysis_file, 'analysis/mean_sweep_response_dg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_sweep_response.shape)\n",
    "\n",
    "mean_sweep_response = np.array(mean_sweep_response)\n",
    "plt.figure();\n",
    "plt.plot(mean_sweep_response[:, 0], mean_sweep_response[:, 1], 'k.')\n",
    "plt.xlabel('roi 1 response')\n",
    "plt.ylabel('roi 0 response')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The mean sweep response object is the trial-averaged df/f. Let's get it from events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_response_table(traces, stim_table, stim_type):\n",
    "\n",
    "    '''\n",
    "    param traces: units x time trace of activity\n",
    "    param stim_table: dictionary of stimulus start / stop times and identities\n",
    "    param stim_type: one of boc.get_all_stimuli()\n",
    "    \n",
    "    returns: numpy array of size (stimulus trials, units) with the summed activity in each trial\n",
    "    '''\n",
    "    \n",
    "    Ncells = traces.shape[0]\n",
    "    Nstim = len(stim_table)\n",
    "\n",
    "    ind_start = stim_table.start.values\n",
    "    ind_end = stim_table.end.values\n",
    "\n",
    "    response_array = np.zeros((Nstim, Ncells))\n",
    "    for i in range(Nstim):\n",
    "        response_array[i] = np.mean(traces[:, ind_start[i]:ind_end[i]], axis=1)\n",
    "\n",
    "    return response_array  # stim x cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sweep_response_events = get_response_table(traces=events, stim_table=stim_table, stim_type='drifting_gratings')\n",
    "\n",
    "X = np.array(mean_sweep_response_events)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "plt.plot(mean_sweep_response[:, 0]/100., mean_sweep_response_events[:, 0], 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_category = 'orientation'\n",
    "Y = np.array(stim_table[stim_category]) # get stimulus labels\n",
    "Y[~np.isfinite(Y)] = -45 # give blank stim a nicer label\n",
    "\n",
    "print(Y[:10])\n",
    "print(np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, :2] # pick two neurons\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "# LDA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA.fit(X, Y)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(.5, LDA.score(X, Y), width=0.2)\n",
    "plt.ylabel('Training score'); plt.xlim((0, 1)); plt.ylim((0, 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we tell what points this trained classifier will classify as each direction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decision_surface2d(x_plot, y_plot, classifier):\n",
    "    \n",
    "    '''\n",
    "    param x: range for x axis\n",
    "    param y: range for y axis\n",
    "    param classifier: trained classifier with predict method\n",
    "    '''\n",
    "    \n",
    "    xx, yy = np.meshgrid(x_plot, y_plot)\n",
    "    X =(np.c_[xx.ravel(), yy.ravel()])\n",
    "    \n",
    "    return classifier.predict(X).reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(-1, 1, 100)\n",
    "\n",
    "plt.figure();\n",
    "plt.imshow(decision_surface2d(x_plot, x_plot, LDA), interpolation='none', extent=(-1, 1, 1, -1), clim=(-45, 315));\n",
    "plt.xlabel('possible roi 1 response'); plt.ylabel('possible roi 0 response')\n",
    "cbar = plt.colorbar(); plt.text(1.6, 0, 'Orientation', rotation=90, verticalalignment='center');\n",
    "cbar.set_ticks(np.unique(Y))\n",
    "cbar.set_ticklabels(['blank']+np.unique(Y)[1:].astype('int').tolist() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How sensitive is the decision surface to the amount of training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = range(10, 12)\n",
    "\n",
    "x_min = -1.5 * np.amax(X[:num_points[-1]])\n",
    "x_plot = np.linspace(x_min, -1*x_min, 100)\n",
    "\n",
    "Nplots = len(num_points)\n",
    "if Nplots % 2 != 0: Nplots += 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "for n, ax in enumerate(fig.axes):\n",
    "    \n",
    "    num = num_points[n]\n",
    "    LDA.fit(X[:num], Y[:num])\n",
    "    \n",
    "    im = ax.imshow(decision_surface2d(x_plot, x_plot, LDA), interpolation='none', extent=(x_min, -1*x_min, -1*x_min, x_min), clim=(-45, 315))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.plot(X[:num, 0], X[:num, 1], 'k.')\n",
    "    ax.plot(0, 0, 'r.')\n",
    "    ax.set_title(str(num)+' points', fontsize=16)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "fig.text(.5, .01, 'roi 1 response', horizontalalignment='center')\n",
    "fig.text(.05, .5, 'roi 0 response', rotation=90, verticalalignment='center')\n",
    "\n",
    "cbar = fig.colorbar(im, ax=fig.axes)\n",
    "fig.text(.87, .5, 'Orientation', rotation=90, verticalalignment='center')\n",
    "cbar.set_ticks(np.unique(Y))\n",
    "cbar.set_ticklabels(['blank']+np.unique(Y)[1:].astype('int').tolist() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y[:10])\n",
    "print(Y[:11])\n",
    "print(X[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = range(10, 16)\n",
    "\n",
    "x_min = -1.5 * np.amax(X[:num_points[-1]])\n",
    "x_plot = np.linspace(x_min, -1*x_min, 100)\n",
    "                     \n",
    "Nplots = len(num_points)\n",
    "if Nplots % 2 != 0: Nplots += 1\n",
    "\n",
    "fig, ax = plt.subplots(2, Nplots/2, figsize=(10, 6))\n",
    "\n",
    "for n, ax in enumerate(fig.axes):\n",
    "    \n",
    "    num = num_points[n]\n",
    "    LDA.fit(X[:num], Y[:num])\n",
    "    \n",
    "    im = ax.imshow(decision_surface2d(x_plot, x_plot, LDA), interpolation='none', extent=(x_min, -1*x_min, -1*x_min, x_min), clim=(-45, 315))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.plot(X[:num, 0], X[:num, 1], 'k.')\n",
    "    ax.plot(0, 0, 'r.')\n",
    "    ax.set_title(str(num)+' points', fontsize=16)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "fig.text(.5, .01, 'roi 1 response', horizontalalignment='center')\n",
    "fig.text(.05, .5, 'roi 0 response', rotation=90, verticalalignment='center')\n",
    "\n",
    "cbar = fig.colorbar(im, ax=fig.axes)\n",
    "cbar.set_ticks(np.unique(Y))\n",
    "cbar.set_ticklabels(['blank']+np.unique(Y)[1:].astype('int').tolist() )\n",
    "fig.text(.87, .5, 'Orientation', rotation=90, verticalalignment='center')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF;\">\n",
    "<p>In order to avoid over-fitting, we should evaluate our classifier on different data than we used to train it. This is called cross-validation. If we have a data set of K points, we can hold out a fraction of our data to use as testing data. The classifier's ability to generalize shows us how it can learn the class distributions, rather than the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, LeaveOneOut, StratifiedKFold\n",
    "# check sklearn.cross_validation if your version doesn't have model_selection\n",
    "\n",
    "n_splits = 2\n",
    "kf = StratifiedKFold(n_splits=n_splits)\n",
    "kf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 4), sharex=True, sharey=True)\n",
    "\n",
    "for train, test in kf.split(X, Y):\n",
    "    ax[0].plot(X[train, 0], X[train, 1], '.', label='fold '+str(n))\n",
    "    ax[1].plot(X[test, 0], X[test, 1], '.', label='fold '+str(n))\n",
    "    n += 1\n",
    "    \n",
    "ax[0].set_title('Train')\n",
    "ax[1].set_title('Test')\n",
    "ax[0].legend(loc=0, frameon=False)\n",
    "fig.text(.5, .01, 'roi 1 response', horizontalalignment='center')\n",
    "fig.text(.01, .5, 'roi 0 response', rotation=90, verticalalignment='center')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "n = 0\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "for train, test in kf.split(X, Y):\n",
    "    LDA.fit(X[train], Y[train])\n",
    "    \n",
    "    if n == 0:\n",
    "        ax.bar(n-.25, LDA.score(X[train], Y[train]), facecolor='k', width=0.5, label='Train')\n",
    "        ax.bar(n+.25, LDA.score(X[test], Y[test]), facecolor='r', width=0.5, label='Test')\n",
    "    else:\n",
    "        ax.bar(n-.25, LDA.score(X[train], Y[train]), facecolor='k', width=0.5)\n",
    "        ax.bar(n+.25, LDA.score(X[test], Y[test]), facecolor='r', width=0.5)\n",
    "\n",
    "    n += 2\n",
    "\n",
    "ax.set_xticks(range(0, n_splits*2, 2))\n",
    "ax.set_xticklabels(range(0, n_splits))\n",
    "ax.set_xlabel('Fold')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim((0, .3))\n",
    "ax.legend(loc='upper left', frameon=False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do the scores evolve as we use more training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "num_total = X.shape[0]\n",
    "train_sizes, train_scores, test_scores = learning_curve(LDA, X, Y, cv=5, train_sizes=np.arange(.1, 1.1, .1));\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, train_scores, 'b');\n",
    "plt.plot(train_sizes, test_scores, 'r');\n",
    "plt.xlabel('Training points'); plt.ylabel('Score'); #plt.legend(loc=0, frameon=False);\n",
    "plt.text(100, .6, 'Train', color='b')\n",
    "plt.text(100, .5, 'Test', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
